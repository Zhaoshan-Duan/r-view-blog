---
title: 'Modernizing *Intro to Statistics* with `infer` - Part 1: T-test'
author: "Zhaoshan Duan, Lydia Gibson"
date: '2021-01-24'
output:
  word_document: default
  pdf_document: default
  html_document:
    df_print: paged
editor_options:
  markdown:
    wrap: 72
---

```{r include=FALSE}
library(tidyverse)
library(infer)
```

In this blog series, we aim to advocate for the modernization of statistical inference in *"Intro to Statistics"* courses by using the [`infer`](https://infer.netlify.app/) package. The `infer` package features tidyverse-friendly wrapper functions to perform inferences and
consolidates a [unified workflow framework](http://allendowney.blogspot.com/2016/06/there-is-still-only-one-test.html), which encompasses the essence of hypothesis testing.

Throughout the series, we plan to compare and contrast the classical approach of conducting hypothesis testing using **base R** functions with the [`infer`](https://infer.netlify.app/) workflow on some of the most popular statistical topics covered in introductory statistics classes. Our goal in each blog is to demonstrate how the `infer` framework adds additional workflow explainability and procedural clarity to the classical hypothesis testing approach.

![FIGURE 1.1 Hypothesis testing with the infer
package](https://d33wubrfki0l68.cloudfront.net/391315f52b3be002b49628738e22cfd6dae7cae1/cff0f/images/flowcharts/infer/ht.png)

In this first blog, we are focusing on conducting **Two-sample T-test** and compute confidence interval using the `ncbirths` dataset from [*OpenIntro Statistics*](https://www.openintro.org/book/os/). We start with a quick overview of the dataset then proceed to a step-by-step analysis using the `infer` pipeline. To clearly demonstrate comparison, we include a brief discussion on the classical approach for each corresponding step of the `infer` framework. 

Last Updated: `r format(Sys.time(), '%B %d, %Y')`

# Data

Throughout this post, we make use of the `ncbirths` dataset from the `openintro` package. 
```{r warning=FALSE}
library(openintro)
data(ncbirths)
```

`ncbirths` records 1000 cases of North Carolina births in 2004, and has been of interest to medical researchers on studying the relation between habits and practices of expectant mothers and the birth of their children. The data looks like this:
```{r data-overview, warning=FALSE}
str(ncbirths)
head(ncbirths)
```

In the case of `ncbirths`, we study the mean difference between the expectant mothers' smoking status by looking their babies' weights. From observing the box plot below, we see that babies from mothers that smoke seem to weigh less than babies from mother that do not smoke. However, the difference can be due to sampling. To determine if this difference is statistically significant, we conduct **Two-sample T-test**. 

```{r}
ncbirths %>% 
  select(habit, weight) %>% 
  drop_na() %>% 
  ggplot(aes(x = habit, y = weight)) +
  geom_boxplot()+ 
   labs(x = "Smoking status of mother", y = "Birth weight of baby (in lbs)")
```

# `specify()`
First, we need to specify the variables of interest. In this case, they are `weight`, weight of the baby at birth in pounds, and `habit`, status of the mother as a `nonsmoker` or a `smoker`. In **base R**, we can choose to manually subset the variables:

```{r}
nc_nosmoker<- subset(ncbirths ,habit == "nonsmoker")
nc_smoker<- subset(ncbirths ,habit == "smoker")
```

Using `specify()`, we can write:

```{r}
ncbirths %>% 
  specify(weight ~ habit)
```

# `hypothesize()`

The next step is to declare the null hypothesis. For our research question, we are examining the weight difference between babies whose mothers do or do not smoke. We thus construct the following hypothesis: 

$$
\begin{aligned}
H_0: \mu_{\text{nonsmoker}} - \mu_{\text{smoker}} = 0\\
H_A: \mu_{\text{nonsmoker}} - \mu_{\text{smoker}} \ne 0 
\end{aligned}
$$
In **base R**, this step is normally done on *actual* paper and assumed when we run `t.test()`. However, with `infer`, we can use `hypothesize()` and set `null = "independence"` since we have two samples. 

```{r}
ncbirths %>% 
  specify(weight ~ habit) %>% 
  hypothesize(null = "independence")
```

# `generate()`

After asserting our null hypothesis, we construct a null distribution via permutation. We will obtain 1000 observations that are "shuffled". 

```{r}
ncbirths %>% 
  specify(weight ~ habit) %>% 
  hypothesize(null = "independence") %>% 
  generate(reps = 1000, type = "permute")
```

# `calculate()`
We next calculate the appropriate summary statistics of the null distribution, and the observed statistics.

```{r}
null_dist <- ncbirths %>% 
  specify(weight ~ habit) %>% 
  hypothesize(null = "independence") %>% 
  generate(reps = 1000, type = "permute") %>% 
  calculate(stat = "diff in means", order = c("nonsmoker", "smoker"))
```

```{r}
observed_statistic <-ncbirths %>% 
  specify(weight ~ habit) %>% 
  calculate(stat = "diff in means", order = c("nonsmoker", "smoker"))

observed_statistic
```


```{r}
x <- t.test(weight ~ habit, data=ncbirths)
```


```{r}
x_1 <- x$conf.int[[1]]
```


We construct the hypothesis test, and use `t.test()` to examine whether
the mean difference between the nonsmoker and smoker mothers is
statistically significant, and calculate confidence interval for the
difference between the two.


```{r}
obs_diff_prop <- ncbirths %>% 
  specify(weight ~ habit) %>% 
  calculate(stat = "diff in means", order = c("nonsmoker", "smoker"))

```

```{r}
null_dist %>% 
  get_p_value(obs_stat = observed_statistic, direction = "right")
```
 

# `visualize()`


```{r}
visualize(null_dist, bins = 10) + 
  shade_p_value(obs_stat = observed_statistic, direction = "two-sided")
```

# `get_confidence_interval()`

```{r}
bootstrap_distribution <- ncbirths %>% 
  specify(weight ~ habit) %>% 
  generate(reps = 1000, type = "bootstrap") %>% 
  calculate(stat = "diff in means", order = c("nonsmoker", "smoker"))

percentile_ci <- bootstrap_distribution %>% 
  get_confidence_interval(level = 0.95, type = "percentile")
```

Plot the mean difference

Alternative

```{r}
wtg_diff <- nc_nosmoker$weight - nc_smoker$weight
#wtg_diff <- wtg_diff[!is.na(wtg_diff)] # remove missing entries (NA values)

n <- length(ncbirths)

wtg_diff 

hist(wtg_diff, breaks=100, xlim=c(-0.4,0.4))
```

### `infer`

In `infer` package provides a series of functions that provides more
clarity to the process. Under the hood, these functions are wrapper
functions to the base R functions we used in the previous
[section](#base).

Null distribution:

```{r warning=FALSE}
set.seed(42)
null <- ncbirths %>% 
  specify(weight ~ habit) %>%
  hypothesize(null = "independence") %>%
  generate(reps = 1000, type = "permute") %>%
  calculate(stat = "diff in means", order = c("nonsmoker", "smoker"))
```

```{r warning=FALSE}
observed <- ncbirths %>% 
  specify(weight ~ habit) %>%
  calculate(stat = "diff in means", order = c("nonsmoker", "smoker"))
```

p-value:

```{r}
null %>% 
  get_p_value(obs_stat = observed, direction = "right")
```

Visualization p-value

```{r}
visualize(null, bins = 20) + 
  shade_p_value(obs_stat = observed, direction = "right") + labs(x="mean difference")
```

Or using wrapper function

```{r}
t_test(x = ncbirths, 
       formula = weight ~ habit, 
       order = c("nonsmoker", "smoker"),
       alternative = "two-sided")
```

# Next Part

As students, we were overwhelmed by the use of p-values, various statistical tests, and the corresponding interpretations when hypothesis
testing was first introduced. It only gets better once students acquire the realization and intuition of the [universal pattern](http://allendowney.blogspot.com/2016/06/there-is-still-only-one-test.html) that statistical tests follow through advanced courses.

Moreover, simulation-based inferences are often more visual and intuitive than analytical inferences. While many educators include those numerical approaches in their teaching, it often feels segmented, especially in base R code.

We hope this blog post could provide students' perspectives on statistical education and shed light on the discussion of modernizing "Intro to Statistics" courses.

Follow-up tidymodel.

