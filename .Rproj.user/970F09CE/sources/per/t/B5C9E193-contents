---
title: 'Modernizing *Intro to Statistics* with `infer` - Part 1:
  T-test'
author: "Zhaoshan Duan, Lydia Gibson"
date: "2021-01-24"
output:
  html_document:
    df_print: paged
editor_options:
  markdown:
    wrap: 72
---

```{r include=FALSE}
library(tidyverse)
library(infer)
library(openintro)
```

In this blog series, we aim to advocate for the modernization of statistical inference in *"Intro to Statistics"* courses by using the [`infer`](https://infer.netlify.app/) package. The `infer` package features tidyverse-friendly wrapper functions to perform inferences and
consolidates a [unified workflow framework](http://allendowney.blogspot.com/2016/06/there-is-still-only-one-test.html), which encompasses the essence of hypothesis testing.

Throughout the series, we plan to compare and contrast the classical approach of conducting hypothesis testing using **base R** functions with the [`infer`](https://infer.netlify.app/) workflow on some of the most popular statistical topics covered in introductory statistics classes. Our goal in each blog is to demonstrate how the `infer` framework adds additional workflow explainability and procedural clarity to the classical hypothesis testing approach.

![FIGURE 1.1 Hypothesis testing with the infer
package](https://d33wubrfki0l68.cloudfront.net/391315f52b3be002b49628738e22cfd6dae7cae1/cff0f/images/flowcharts/infer/ht.png)

In this first blog, we are focusing on conducting **Two-sample T-test** and compute confidence interval using the `ncbirths` dataset from [*OpenIntro Statistics*](https://www.openintro.org/book/os/). We start with a quick overview of the dataset then proceed to a step-by-step analysis using `infer` pipeline. To clearly demonstrate comparison, for each step of the `infer` framework, we include a brief discussion on the corresponding classical approach.

Last Updated: `r format(Sys.time(), '%B %d, %Y')`

# Data

`ncbirths` records 1000 cases of North Carolina births in 2004, and has been of interest to medical researchers on studying the relation between habits and practices of expectant mothers and the birth of their children. The data looks like this:

```{r data-overview}
data(ncbirths)
str(ncbirths)
head(ncbirths)
```

To conduct **Two-sample T-test**, we study the relationship between the
mother's smoking status, and the baby's weight.

# `specify()`

First, we need to specify the variables of interest. In this case, they are `weight` and `habit`. Uinsg `specify()`, we can write:

```{r}
ncbirths %>% 
  specify(weight ~ habit)
```

In **base R**, we can choose manually subset the variables:

```{r}
nc_nosmoker<- subset(ncbirths ,habit == "nonsmoker")
nc_smoker<- subset(ncbirths ,habit == "smoker")
```

# `hypothesize()`

The next step is to declare the null hypothesis. For our research question, we are examining the weight difference between babies from mothers that smoke and babies from mother that do no smoke. We thus construct the following hypothesis: 

$$
\begin{aligned}
H_0: \mu_{\text{nonsmoker}} - \mu_{\text{smoker}} = 0\\
H_A: \mu_{\text{nonsmoker}} - \mu_{\text{smoker}} \ne 0 
\end{aligned}
$$
In **base R**, this step is normally done on actual paper and assumed when we run `t.test()`. However, with `infer`, we can use `hypothesize()` and set `null = "independence"` since we have two samples. 

```{r}
ncbirths %>% 
  specify(weight ~ habit) %>% 
  hypothesize(null = "independence")
```

# `generate()`

After asserting our null hypothesis, we construct a null distribution via permutation. We will obtain 1000 observations that are "shuffled". 

```{r}
ncbirths %>% 
  specify(weight ~ habit) %>% 
  hypothesize(null = "independence") %>% 
  generate(reps = 1000, type = "permute")
```

# `calculate()`
We next calculate the appropriate summary statistics of the null distribution, and the observed statistics.

```{r}
null_dist <- ncbirths %>% 
  specify(weight ~ habit) %>% 
  hypothesize(null = "independence") %>% 
  generate(reps = 1000, type = "permute") %>% 
  calculate(stat = "diff in means", order = c("nonsmoker", "smoker"))
```

```{r}
observed_statistic <-ncbirths %>% 
  specify(weight ~ habit) %>% 
  calculate(stat = "diff in means", order = c("nonsmoker", "smoker"))

observed_statistic
```


```{r}
t.test(weight ~ habit, data=ncbirths)
```

We construct the hypothesis test, and use `t.test()` to examine whether
the mean difference between the nonsmoker and smoker mothers is
statistically significant, and calculate confidence interval for the
difference between the two.


```{r}
obs_diff_prop <- ncbirths %>% 
  specify(weight ~ habit) %>% 
  calculate(stat = "diff in means", order = c("nonsmoker", "smoker"))

```

```{r}
null_dist %>% 
  get_p_value(obs_stat = observed_statistic, direction = "right")
```
 

# `visualize()`


```{r}
visualize(null_dist, bins = 10) + 
  shade_p_value(obs_stat = observed_statistic, direction = "two-sided")
```

# `get_confidence_interval()`

```{r}
bootstrap_distribution <- ncbirths %>% 
  specify(weight ~ habit) %>% 
  generate(reps = 1000, type = "bootstrap") %>% 
  calculate(stat = "diff in means", order = c("nonsmoker", "smoker"))

percentile_ci <- bootstrap_distribution %>% 
  get_confidence_interval(level = 0.95, type = "percentile")
percentile_ci
```



Plot the mean difference

Alternative

```{r}
wtg_diff <- nc_nosmoker$weight - nc_smoker$weight
#wtg_diff <- wtg_diff[!is.na(wtg_diff)] # remove missing entries (NA values)

n <- length(ncbirths)

wtg_diff 

hist(wtg_diff, breaks=100, xlim=c(-0.4,0.4))
```

### `infer`

In `infer` package provides a series of functions that provides more
clarity to the process. Under the hood, these functions are wrapper
functions to the base R functions we used in the previous
[section](#base).

Null distribution:

```{r warning=FALSE}
set.seed(42)
null <- ncbirths %>% 
  specify(weight ~ habit) %>%
  hypothesize(null = "independence") %>%
  generate(reps = 1000, type = "permute") %>%
  calculate(stat = "diff in means", order = c("nonsmoker", "smoker"))
```

```{r warning=FALSE}
observed <- ncbirths %>% 
  specify(weight ~ habit) %>%
  calculate(stat = "diff in means", order = c("nonsmoker", "smoker"))
```

p-value:

```{r}
null %>% 
  get_p_value(obs_stat = observed, direction = "right")
```

Visualization p-value

```{r}
visualize(null, bins = 20) + 
  shade_p_value(obs_stat = observed, direction = "right") + labs(x="mean difference")
```

Or using wrapper function

```{r}
t_test(x = ncbirths, 
       formula = weight ~ habit, 
       order = c("nonsmoker", "smoker"),
       alternative = "two-sided")
```

# Next Part

As students, we were overwhelmed by the use of p-values, various
statistical tests, and the corresponding interpretations when hypothesis
testing was first introduced.

Treat as a programming problem, not as math problem.

Follow-up tidymodel.

## Suess' note

How to get the R notebook to have the steps fully demonstrated. - -
hypothesis - go through t.test - classical interpretation vs. simulation
interpretaion

Traditionally, only uses t.test(), not aligned with the modern workflow.

modern programming workflow breaks things down, moderndive workflow.

Much better in demonstrating the workflow,

Hypothesis testing is a workflow.

explanability: - "run t.test" what does it mean to the team - `t.test()`

a tool to see what you're doing.

statistics cannot be taughted the same way as Math, but as programming.

Instead of generating p-values

emphasizing data and simulations instead of theory and tests.

a modernized approach of introducing hypothesis testing as a workflow
framework in .

It only gets better once students acquire the realization and intuition
of the [universal
pattern](http://allendowney.blogspot.com/2016/06/there-is-still-only-one-test.html)
that statistical tests follow through advanced courses.

Moreover, simulation-based inferences are often more visual and
intuitive than analytical inferences. While many educators include those
numerical approaches in their teaching, it often feels segmented,
especially in base R code.

We hope this blog post could provide students' perspectives on
statistical education and shed light on the discussion of modernizing
"Intro to Statistics" courses.
